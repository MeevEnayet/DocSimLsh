{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the Documents\n",
    "def preprocess_document(doc):\n",
    "    doc = doc.lower()\n",
    "    doc = re.sub(r'\\W+', ' ', doc)\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Shingles\n",
    "def shingle(text, k):\n",
    "    shingle_set = set()\n",
    "    for i in range(len(text) - k + 1):\n",
    "        shingle_set.add(text[i:i+k])\n",
    "    return shingle_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample documents\n",
    "#a = \"flying fish flew by the space station\"\n",
    "#b = \"he will not allow you to bring your sticks of dynamite and pet armadillo along\"\n",
    "#c = \"he figured a few sticks of dynamite were easier than a fishing pole to catch an armadillo\"\n",
    "\n",
    "a= \"The quick brown fox jumps over the lazy dog.\"\n",
    "#b=\"Never jump over the lazy dog quickly.\"\n",
    "c=\"A fox is quick and brown and it jumps over dogs.\"\n",
    "b=\"The quick brown fox jumps over the lazy dog1.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shingles for document a: {' l', 'ui', 'br', 'ox', 'he', 'r ', ' b', ' o', 'g ', ' d', 'wn', 'e ', 'er', 'la', 've', 'az', ' f', 'ck', 'th', 'do', ' q', 'n ', 'y ', 'mp', 'k ', 'fo', ' t', 'ro', 'ov', 'um', 'ps', 'ic', 's ', ' j', 'ju', 'zy', 'ow', 'x ', 'og', 'qu'}\n",
      "Shingles for document b: {' l', 'ui', 'br', 'ox', 'he', 'r ', '1 ', ' b', 'g1', ' o', ' d', 'wn', 'e ', 'er', 'la', 've', 'az', ' f', 'ck', 'th', 'do', ' q', 'n ', 'y ', 'mp', 'k ', 'fo', ' t', 'ro', 'ov', 'um', 'ps', 'ic', 's ', ' j', 'ju', 'zy', 'ow', 'x ', 'og', 'qu'}\n",
      "Shingles for document c: {'ui', 'is', 'gs', 'br', 'ox', 'r ', ' b', ' a', ' o', ' d', 'wn', 'er', 've', ' f', 't ', 'a ', 'an', 'd ', 'ck', 'do', ' q', 'n ', 'it', 'nd', 'mp', 'k ', 'fo', ' i', 'ro', 'ov', 'um', 'ps', 'ic', 's ', ' j', 'ju', 'ow', 'x ', 'og', 'qu'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Preprocess and generate shingles for each document\n",
    "k = 2\n",
    "a_shingles = shingle(preprocess_document(a), k)\n",
    "b_shingles = shingle(preprocess_document(b), k)\n",
    "c_shingles = shingle(preprocess_document(c), k)\n",
    "\n",
    "print(\"Shingles for document a:\", a_shingles)\n",
    "print(\"Shingles for document b:\", b_shingles)\n",
    "print(\"Shingles for document c:\", c_shingles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: ['ui', 'is', 'r ', 'he', '1 ', ' b', ' a', ' d', 'wn', 'la', 't ', 'a ', 'ck', ' q', 'n ', 'it', 'mp', 'nd', 'k ', 'ov', ' j', 'ju', 'zy', 'ow', 'x ', 'qu', ' l', 'gs', 'br', 'ox', 'g1', ' o', 'g ', 'er', 'e ', 've', 'az', ' f', 'an', 'd ', 'th', 'do', 'y ', 'fo', ' t', ' i', 'ro', 'um', 'ps', 'ic', 's ', 'og']\n"
     ]
    }
   ],
   "source": [
    "# Create vocabulary\n",
    "vocab = list(a_shingles.union(b_shingles).union(c_shingles))\n",
    "print(\"Vocabulary:\", vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-Hot Encoding for document a: [1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1]\n",
      "One-Hot Encoding for document b: [1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1]\n",
      "One-Hot Encoding for document c: [1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# One-Hot Encoding\n",
    "def one_hot_encode(shingles, vocab):\n",
    "    return [1 if shingle in shingles else 0 for shingle in vocab]\n",
    "\n",
    "a_1hot = one_hot_encode(a_shingles, vocab)\n",
    "b_1hot = one_hot_encode(b_shingles, vocab)\n",
    "c_1hot = one_hot_encode(c_shingles, vocab)\n",
    "\n",
    "print(\"One-Hot Encoding for document a:\", a_1hot)\n",
    "print(\"One-Hot Encoding for document b:\", b_1hot)\n",
    "print(\"One-Hot Encoding for document c:\", c_1hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create hash functions\n",
    "def create_hash_func(size):\n",
    "    hash_ex = list(range(1, size + 1))\n",
    "    shuffle(hash_ex)\n",
    "    return hash_ex\n",
    "\n",
    "def build_minhash_func(vocab_size, num_perm):\n",
    "    hashes = []\n",
    "    for _ in range(num_perm):\n",
    "        hashes.append(create_hash_func(vocab_size))\n",
    "    return hashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinHash Signature for document a: [51, 19, 44, 13, 43, 34, 41, 44, 42, 48]\n",
      "MinHash Signature for document b: [51, 19, 30, 13, 43, 34, 41, 44, 42, 48]\n",
      "MinHash Signature for document c: [51, 19, 38, 27, 43, 35, 15, 45, 18, 48]\n"
     ]
    }
   ],
   "source": [
    "# Generate MinHash signatures\n",
    "num_perm = 128\n",
    "minhash_funcs = build_minhash_func(len(vocab), num_perm)\n",
    "\n",
    "def create_signature(one_hot_vector, minhash_funcs):\n",
    "    signature = []\n",
    "    for func in minhash_funcs:\n",
    "        for i in range(1, len(vocab) + 1):\n",
    "            idx = func.index(i)\n",
    "            if one_hot_vector[idx] == 1:\n",
    "                signature.append(idx)\n",
    "                break\n",
    "    return signature\n",
    "\n",
    "a_signature = create_signature(a_1hot, minhash_funcs)\n",
    "b_signature = create_signature(b_1hot, minhash_funcs)\n",
    "c_signature = create_signature(c_1hot, minhash_funcs)\n",
    "\n",
    "print(\"MinHash Signature for document a:\", a_signature[:10])\n",
    "print(\"MinHash Signature for document b:\", b_signature[:10])\n",
    "print(\"MinHash Signature for document c:\", c_signature[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinHashLSH:\n",
    "    def __init__(self, threshold=0.5, num_perm=128, bands=10):\n",
    "        self.threshold = threshold\n",
    "        self.num_perm = num_perm\n",
    "        self.bands = bands\n",
    "        self.rows = num_perm // bands\n",
    "        self.buckets = [{} for _ in range(bands)]\n",
    "    \n",
    "    def _get_band_hashes(self, minhash):\n",
    "        band_hashes = []\n",
    "        for i in range(self.bands):\n",
    "            band = tuple(minhash[i*self.rows:(i+1)*self.rows])\n",
    "            band_hashes.append(hash(band))\n",
    "        return band_hashes\n",
    "    \n",
    "    def insert(self, key, minhash):\n",
    "        band_hashes = self._get_band_hashes(minhash)\n",
    "        for i, band_hash in enumerate(band_hashes):\n",
    "            if band_hash not in self.buckets[i]:\n",
    "                self.buckets[i][band_hash] = []\n",
    "            self.buckets[i][band_hash].append(key)\n",
    "    \n",
    "    def query(self, minhash):\n",
    "        band_hashes = self._get_band_hashes(minhash)\n",
    "        candidates = set()\n",
    "        for i, band_hash in enumerate(band_hashes):\n",
    "            if band_hash in self.buckets[i]:\n",
    "                candidates.update(self.buckets[i][band_hash])\n",
    "        return list(candidates)\n",
    "\n",
    "# Apply LSH\n",
    "lsh = MinHashLSH(threshold=0.5, num_perm=num_perm, bands=10)\n",
    "lsh.insert('a', a_signature)\n",
    "lsh.insert('b', b_signature)\n",
    "lsh.insert('c', c_signature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents similar to document 'a': ['b', 'a']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Query for similar documents to document 'a'\n",
    "similar_docs = lsh.query(a_signature)\n",
    "print(\"Documents similar to document 'a':\", similar_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
